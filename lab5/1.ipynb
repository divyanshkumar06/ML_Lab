{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "049df7ba",
   "metadata": {},
   "source": [
    "baseline performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e96dae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ebc4aee",
   "metadata": {},
   "outputs": [],
   "source": [
    " df=sns.load_dataset(\"iris\") #load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adf881a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width    species\n",
       "0             5.1          3.5           1.4          0.2     setosa\n",
       "1             4.9          3.0           1.4          0.2     setosa\n",
       "2             4.7          3.2           1.3          0.2     setosa\n",
       "3             4.6          3.1           1.5          0.2     setosa\n",
       "4             5.0          3.6           1.4          0.2     setosa\n",
       "..            ...          ...           ...          ...        ...\n",
       "145           6.7          3.0           5.2          2.3  virginica\n",
       "146           6.3          2.5           5.0          1.9  virginica\n",
       "147           6.5          3.0           5.2          2.0  virginica\n",
       "148           6.2          3.4           5.4          2.3  virginica\n",
       "149           5.9          3.0           5.1          1.8  virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd860dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df[\"species\"]).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b13a41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5736\\980429767.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"species\"] = df[\"species\"].replace(class_map)\n"
     ]
    }
   ],
   "source": [
    "# Map species to numeric\n",
    "class_map = {\"setosa\": 0, \"versicolor\": 1, \"virginica\": 2}\n",
    "df[\"species\"] = df[\"species\"].replace(class_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdc6cad",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19dda51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(X, y, alpha=0.1, epochs=1000):\n",
    "    n_samples, n_features = X.shape\n",
    "    w = np.zeros((n_features, 1))       # column vector\n",
    "    y = y.reshape(-1, 1)                # ensure column vector\n",
    "    loss_history = []\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        y_pred = X @ w                  # (n_samples,1)\n",
    "        error = y_pred - y              # (n_samples,1)\n",
    "        gradient = (1 / n_samples) * (X.T @ error)  # (n_features,1)\n",
    "        w -= alpha * gradient           # update\n",
    "        loss = (1 / (2 * n_samples)) * np.sum(error ** 2)  # MSE\n",
    "        loss_history.append(loss)\n",
    "\n",
    "    return w, loss_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8644cc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X, y, w, name=\"Model\"):\n",
    "    predictions = [sum(w[j] * x[j] for j in range(len(x))) + w[-1] for x in X]\n",
    "    avg_error = np.mean(np.abs(np.array(predictions) - y))\n",
    "    print(f\"{name} Average Absolute Error: {avg_error:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4bdf76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred, name=\"Model\"):\n",
    "    accuracy = np.mean(y_true == y_pred)\n",
    "    precision_list, recall_list, f1_list = [], [], []\n",
    "\n",
    "    for c in np.unique(y_true):\n",
    "        tp = np.sum((y_pred == c) & (y_true == c))\n",
    "        fp = np.sum((y_pred == c) & (y_true != c))\n",
    "        fn = np.sum((y_pred != c) & (y_true == c))\n",
    "\n",
    "        precision = tp / (tp + fp + 1e-9)\n",
    "        recall = tp / (tp + fn + 1e-9)\n",
    "        f1 = 2 * precision * recall / (precision + recall + 1e-9)\n",
    "\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_list.append(f1)\n",
    "\n",
    "    print(f\"\\n{name} Results:\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Precision: {np.mean(precision_list):.2f}\")\n",
    "    print(f\"Recall: {np.mean(recall_list):.2f}\")\n",
    "    print(f\"F1 Score: {np.mean(f1_list):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e272f97",
   "metadata": {},
   "source": [
    "# split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c257151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(labels):\n",
    "    classes = sorted(set(labels))\n",
    "    class_to_idx = {c: i for i, c in enumerate(classes)}\n",
    "    Y = np.zeros((len(labels), len(classes)))\n",
    "    for i, label in enumerate(labels):\n",
    "        Y[i, class_to_idx[label]] = 1\n",
    "    return Y, class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f679cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(X, y, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15):\n",
    "    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6, \"Ratios must sum to 1.\"\n",
    "\n",
    "    np.random.seed(42)\n",
    "    indices = np.arange(len(X))\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    # Ensure NumPy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    X = X[indices]\n",
    "    y = y[indices]\n",
    "\n",
    "    n_train = int(train_ratio * len(X))\n",
    "    n_val = int(val_ratio * len(X))\n",
    "\n",
    "    X_train, y_train = X[:n_train], y[:n_train]\n",
    "    X_val, y_val = X[n_train:n_train+n_val], y[n_train:n_train+n_val]\n",
    "    X_test, y_test = X[n_train+n_val:], y[n_train+n_val:]\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1305d6",
   "metadata": {},
   "source": [
    "# implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1aef8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(columns=\"species\")\n",
    "y=df[\"species\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77b71576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sepal_length', 'sepal_width', 'petal_length', 'petal_width'], dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols=X.columns\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66deedd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max(df):\n",
    "    return (df-df.min())/(df.max()-df.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "884c7dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cols:\n",
    "    X[c]=min_max(X[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fdd6129",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test=split(X,y,0.7,0.15,0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "facf356e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dtaset Average Absolute Error: 1.59\n",
      "validation dtaset Average Absolute Error: 1.83\n",
      "test dtaset Average Absolute Error: 1.53\n"
     ]
    }
   ],
   "source": [
    "weights = {}\n",
    "losses = {}\n",
    "\n",
    "w, loss = linear_regression(X_train, y_train, alpha=0.1, epochs=2000)\n",
    "weights[0] = w\n",
    "losses[0] = loss\n",
    "evaluate_model(X_train, y_train,w, \"train dtaset\")\n",
    "\n",
    "w, loss = linear_regression(X_val, y_val, alpha=0.1, epochs=2000)\n",
    "weights[1] = w\n",
    "losses[1] = loss\n",
    "evaluate_model(X_val, y_val,w, \"validation dtaset\")\n",
    "\n",
    "w, loss = linear_regression(X_test, y_test, alpha=0.1, epochs=2000)\n",
    "weights[2] = w\n",
    "losses[2] = loss\n",
    "evaluate_model(X_test, y_test,w, \"test dtaset\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
