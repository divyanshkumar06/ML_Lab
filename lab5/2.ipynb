{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77a4d7ef",
   "metadata": {},
   "source": [
    "oversampling method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c764623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import accuracy_score, mean_squared_error, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3a32359",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=sns.load_dataset(\"iris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdf7a28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width    species\n",
       "0             5.1          3.5           1.4          0.2     setosa\n",
       "1             4.9          3.0           1.4          0.2     setosa\n",
       "2             4.7          3.2           1.3          0.2     setosa\n",
       "3             4.6          3.1           1.5          0.2     setosa\n",
       "4             5.0          3.6           1.4          0.2     setosa\n",
       "..            ...          ...           ...          ...        ...\n",
       "145           6.7          3.0           5.2          2.3  virginica\n",
       "146           6.3          2.5           5.0          1.9  virginica\n",
       "147           6.5          3.0           5.2          2.0  virginica\n",
       "148           6.2          3.4           5.4          2.3  virginica\n",
       "149           5.9          3.0           5.1          1.8  virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99ace885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df[\"species\"]).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86c86bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_25024\\918621057.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"species\"] = df[\"species\"].replace(class_map)\n"
     ]
    }
   ],
   "source": [
    "# Map species to numeric\n",
    "class_map = {\"setosa\": 0, \"versicolor\": 1, \"virginica\": 2}\n",
    "class_unmap = {0:\"setosa\",1: \"versicolor\", 2:\"virginica\"}\n",
    "df[\"species\"] = df[\"species\"].replace(class_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05fa4fa",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6f40bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(X, y, alpha=0.1, epochs=1000):\n",
    "    n_samples, n_features = X.shape\n",
    "    w = np.zeros((n_features, 1))       # column vector\n",
    "    y = y.reshape(-1, 1)                # ensure column vector\n",
    "    loss_history = []\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        y_pred = X @ w                  # (n_samples,1)\n",
    "        error = y_pred - y              # (n_samples,1)\n",
    "        gradient = (1 / n_samples) * (X.T @ error)  # (n_features,1)\n",
    "        w -= alpha * gradient           # update\n",
    "        loss = (1 / (2 * n_samples)) * np.sum(error ** 2)\n",
    "        loss_history.append(loss)\n",
    "\n",
    "    return w, loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "457ed938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "def predict(X, w):\n",
    "    return X.dot(w)\n",
    "\n",
    "# Convert regression outputs → class labels\n",
    "def classify(preds):\n",
    "    return np.round(preds).astype(int).clip(0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3bf957b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrics\n",
    "def evaluate(y_true, y_pred, name=\"Model\"):\n",
    "    accuracy = np.mean(y_true == y_pred)\n",
    "    precision_list, recall_list, f1_list = [], [], []\n",
    "\n",
    "    for c in np.unique(y_true):\n",
    "        tp = np.sum((y_pred == c) & (y_true == c))\n",
    "        fp = np.sum((y_pred == c) & (y_true != c))\n",
    "        fn = np.sum((y_pred != c) & (y_true == c))\n",
    "\n",
    "        precision = tp / (tp + fp + 1e-9)\n",
    "        recall = tp / (tp + fn + 1e-9)\n",
    "        f1 = 2 * precision * recall / (precision + recall + 1e-9)\n",
    "\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_list.append(f1)\n",
    "\n",
    "    print(f\"\\n{name} Results:\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Precision: {np.mean(precision_list):.2f}\")\n",
    "    print(f\"Recall: {np.mean(recall_list):.2f}\")\n",
    "    print(f\"F1 Score: {np.mean(f1_list):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "226ac235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X, y, w, name=\"Model\"):\n",
    "    predictions = [sum(w[j] * x[j] for j in range(len(x))) + w[-1] for x in X]\n",
    "    avg_error = np.mean(np.abs(np.array(predictions) - y))\n",
    "    print(f\"{name} Average Absolute Error: {avg_error:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4262cef",
   "metadata": {},
   "source": [
    "# split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f196d811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(labels):\n",
    "    classes = sorted(set(labels))\n",
    "    class_to_idx = {c: i for i, c in enumerate(classes)}\n",
    "    Y = np.zeros((len(labels), len(classes)))\n",
    "    for i, label in enumerate(labels):\n",
    "        Y[i, class_to_idx[label]] = 1\n",
    "    return Y, class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91fcba3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(X, y, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15):\n",
    "    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6, \"Ratios must sum to 1.\"\n",
    "\n",
    "    np.random.seed(42)\n",
    "    indices = np.arange(len(X))\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    # Ensure NumPy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    X = X[indices]\n",
    "    y = y[indices]\n",
    "\n",
    "    n_train = int(train_ratio * len(X))\n",
    "    n_val = int(val_ratio * len(X))\n",
    "\n",
    "    X_train, y_train = X[:n_train], y[:n_train]\n",
    "    X_val, y_val = X[n_train:n_train+n_val], y[n_train:n_train+n_val]\n",
    "    X_test, y_test = X[n_train+n_val:], y[n_train+n_val:]\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8491e60b",
   "metadata": {},
   "source": [
    "# over sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdfab25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample(X, y, target_class):\n",
    "    X = np.array(X) #feature data\n",
    "    y = np.array(y)#class labels\n",
    "\n",
    "    X_new, y_new = [], []\n",
    "    unique, counts = np.unique(y, return_counts=True) #unique classes and their counts\n",
    "    max_count = max(counts) #sabse zyada kon se class ke sample hai\n",
    "\n",
    "    for c in unique:\n",
    "        X_c = X[y == c]\n",
    "        y_c = y[y == c]\n",
    "\n",
    "        if c == target_class:\n",
    "            while len(X_c) < max_count:\n",
    "                idx = np.random.randint(0, len(X_c))  \n",
    "                X_c = np.vstack([X_c, X_c[idx]]) #add vertically feature data\n",
    "                y_c = np.append(y_c, c)\n",
    "\n",
    "        X_new.append(X_c)\n",
    "        y_new.append(y_c)\n",
    "\n",
    "    return np.vstack(X_new), np.concatenate(y_new)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee4eee3",
   "metadata": {},
   "source": [
    "# implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10972545",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(columns=\"species\")\n",
    "y=df[\"species\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60ecaeaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sepal_length', 'sepal_width', 'petal_length', 'petal_width'], dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols=X.columns\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62808440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max(df):\n",
    "    return (df-df.min())/(df.max()-df.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7975dfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cols:\n",
    "    X[c]=min_max(X[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b40d4ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Minority Class: 0 ===\n",
      "\n",
      "Classifier (minority=setosa) Results:\n",
      "Accuracy: 0.36\n",
      "Precision: 0.33\n",
      "Recall: 0.33\n",
      "F1 Score: 0.33\n",
      "\n",
      "=== Minority Class: 1 ===\n",
      "\n",
      "Classifier (minority=versicolor) Results:\n",
      "Accuracy: 0.35\n",
      "Precision: 0.33\n",
      "Recall: 0.33\n",
      "F1 Score: 0.33\n",
      "\n",
      "=== Minority Class: 2 ===\n",
      "\n",
      "Classifier (minority=virginica) Results:\n",
      "Accuracy: 0.37\n",
      "Precision: 0.33\n",
      "Recall: 0.33\n",
      "F1 Score: 0.33\n"
     ]
    }
   ],
   "source": [
    "for minority_class in [0, 1, 2]:\n",
    "    print(f\"\\n=== Minority Class: {minority_class} ===\")\n",
    "\n",
    "    mask = y != minority_class\n",
    "    keep_idx = np.where(y == minority_class)[0]\n",
    "    keep_idx = np.random.choice(keep_idx, size=len(keep_idx)//2, replace=False)\n",
    "    mask[keep_idx] = True\n",
    "\n",
    "    X_reduced, y_reduced = X[mask], y[mask]\n",
    "\n",
    "    X_bal, y_bal = oversample(X_reduced, y_reduced, minority_class)\n",
    "\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = split(X_bal, y_bal)\n",
    "\n",
    "    w,_ = linear_regression(X_train, y_train, alpha=0.01, epochs=2000)\n",
    "\n",
    "    y_pred = classify(predict(X_test, w))\n",
    "    evaluate(y_test, y_pred, name=f\"Classifier (minority={class_unmap[minority_class]})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
